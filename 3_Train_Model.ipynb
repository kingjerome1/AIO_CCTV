{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 訓練模型並輸出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shliaoc\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras.backend as K\n",
    "from keras.layers import Input, Lambda\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "from yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from yolo3.utils import get_random_data\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main(annotation_path, classes_path, output_model_path):\n",
    "    # return\n",
    "    annotation_path = annotation_path\n",
    "    log_dir = 'logs/000/'\n",
    "    classes_path = classes_path\n",
    "\n",
    "    class_names = get_classes(classes_path)\n",
    "    num_classes = len(class_names)\n",
    "\n",
    "    print(num_classes)\n",
    "    anchors = get_anchors(anchors_path)\n",
    "    \n",
    "\n",
    "    input_shape = (416,416) # multiple of 32, hw\n",
    "\n",
    "    is_tiny_version = len(anchors)==6 # default setting\n",
    "    if is_tiny_version:\n",
    "        model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model/tiny_yolo_weights.h5')\n",
    "    else:\n",
    "        model = create_model(input_shape, anchors, num_classes,\n",
    "            freeze_body=2, weights_path='model/yolo_weights.h5') # make sure you know what you freeze   \n",
    "    # model.save('yolo_model_retrain.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "\n",
    "    print(model.input)\n",
    "    print(model.output)\n",
    "    #plot_model(model, to_file='model_data/retrained_model.png', show_shapes = True)\n",
    "\n",
    "    logging = TensorBoard(log_dir=log_dir)\n",
    "    #checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    #      monitor='loss', save_weights_only=True, save_best_only=False, period=5)\n",
    "    checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}.h5',\n",
    "          monitor='loss', save_weights_only=True, save_best_only=False, period=5)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
    "\n",
    "    val_split = 0.00000001\n",
    "    with open(annotation_path) as f:\n",
    "        lines = f.readlines()\n",
    "    np.random.seed(10101)\n",
    "    np.random.shuffle(lines)\n",
    "    np.random.seed(None)\n",
    "    num_val = int(len(lines)*val_split)\n",
    "    num_train = len(lines) - num_val\n",
    "    \n",
    "    # Unfreeze and continue training, to fine-tune.\n",
    "    # Train longer if the result is not good.\n",
    "    if True:\n",
    "        for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss='mean_squared_error') # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 8 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            #validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            #validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=50,   #loss很大時先不要設太大\n",
    "            initial_epoch=0,\n",
    "            callbacks=[logging, checkpoint])\n",
    "            #callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        # model.save_weights(log_dir + 'trained_weights_final.h5')\n",
    "        # model.save(log_dir + 'trained_model_final.h5')\n",
    "\n",
    "    # Further training if needed.\n",
    "    \n",
    "\n",
    "    # print('model.input = ',model.input)\n",
    "    # print('len(model.layers) = ',len(model.layers))\n",
    "    # print('model.layers[-1]: ',model.layers[-1].output)\n",
    "    # print('model.layers[-2]: ',model.layers[-2].output)\n",
    "    # print('model.layers[-3]: ',model.layers[-3].output)\n",
    "    # print('model.layers[-4]: ',model.layers[-4].output,'\\n')\n",
    "    # # original yolo model outputs:\n",
    "    # print('model.layers[-5]: ',model.layers[-5].output)\n",
    "    # print('model.layers[-6]: ',model.layers[-6].output)\n",
    "    # print('model.layers[-7]: ',model.layers[-7].output)\n",
    "\n",
    "    # save the derived model for detection(using yolo_video.py)\n",
    "    derived_model = Model(model.input[0], [model.layers[249].output, model.layers[250].output, model.layers[251].output])\n",
    "    #plot_model(derived_model, to_file=output_model_path[:-3]+'.png', show_shapes = True)\n",
    "    derived_model.save(output_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):    #weight_path\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    # y_true = [Input(shape=(416//{0:32, 1:16, 2:8}[l], 416//{0:32, 1:16, 2:8}[l], 9//3, 80+5)) for l in range(3)]\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "    print('model_body.input: ', model_body.input)\n",
    "    print('model.input: ', model.input)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)   # input of original yolo: image\n",
    "        box_data = np.array(box_data)       # output of original yolo: boxes\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes) # some kind of output description?!\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotation_path =  dataset/raccoon_train_data.txt\n",
      "classes_path =  dataset/box_classes.txt\n",
      "output_model_path =  model/20210707_Test_ShengYe_Test_model.h5\n",
      "4\n",
      "Create YOLOv3 model with 9 anchors and 4 classes.\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'model/yolo_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-11f65d049216>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output_model_path = '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0m_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mannotation_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_model_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-0ab055e7aafe>\u001b[0m in \u001b[0;36m_main\u001b[1;34m(annotation_path, classes_path, output_model_path)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         model = create_model(input_shape, anchors, num_classes,\n\u001b[1;32m---> 22\u001b[1;33m             freeze_body=2, weights_path='model/yolo_weights.h5') # make sure you know what you freeze   \n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;31m# model.save('yolo_model_retrain.h5')  # creates a HDF5 file 'my_model.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-63b3ad461f30>\u001b[0m in \u001b[0;36mcreate_model\u001b[1;34m(input_shape, anchors, num_classes, load_pretrained, freeze_body, weights_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mload_pretrained\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mmodel_body\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Load weights {}.'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfreeze_body\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   2656\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2657\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2658\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2659\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'model/yolo_weights.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    anchors_path = 'model/yolo_anchors.txt'\n",
    "    \n",
    "    # For Path message\n",
    "    annotation_path = \"dataset/raccoon_train_data.txt\"   # 候選框 TXT檔 位置\n",
    "    classes_path = \"dataset/box_classes.txt\"             # 類別標籤位置\n",
    "    output_model_path = \"model/20210707_Test_ShengYe_Test_model.h5\"       # 輸出的 model 要放的位置\n",
    "    \n",
    "    print('annotation_path = ', annotation_path)\n",
    "    print('classes_path = ', classes_path)\n",
    "    print('output_model_path = ', output_model_path)\n",
    "    \n",
    "    _main(annotation_path, classes_path, output_model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument(\"-a\", \"--annotation_path\", type=str, default='test_data/training_data/annotation.txt', help=\"input annotation_path\")\n",
    "    parser.add_argument(\"-c\", \"--classes_path\", type=str, default='test_data/training_data/pedestrian_classes.txt', help=\"input classes_path\")\n",
    "    parser.add_argument(\"-o\", \"--output_model_path\", type=str, default='model_data/pedestrian_model.h5', help=\"input output_model_path\")\n",
    "    args = parser.parse_args()\n",
    "    print('annotation_path = ', args.annotation_path)\n",
    "    print('classes_path = ', args.classes_path)\n",
    "    print('output_model_path = ', args.output_model_path)\n",
    "\n",
    "    _main(args.annotation_path, args.classes_path, args.output_model_path)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
